{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a9b17e-06a8-4275-bdf5-add205958c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Input, Embedding, Activation, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "import numpy as np\n",
    "from model import dp_syllabler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6b7972-fc36-4ba8-ad64-8cc1579e0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ortho max encoder len = 45\n",
    "#ipa max encoder len = 74\n",
    "\n",
    "with open('data/e2i_ortho.pkl', 'rb') as file:\n",
    "    e2i_ortho = pickle.load(file)\n",
    "    \n",
    "with open('data/e2i_ipa.pkl', 'rb') as file:\n",
    "    e2i_ipa = pickle.load(file)\n",
    "\n",
    "shitter = dp_syllabler(e2i_ortho= e2i_ortho, e2i_ipa = e2i_ipa, ortho_input_size=45,ipa_input_size=74,latent_dim=32,embed_dim=32 ,max_feat=148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4054e97-517f-4b07-90ff-7be738668746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences):\n",
    "        cat_sequences = []\n",
    "        for s in sequences:\n",
    "            cats = []\n",
    "            for item in s:\n",
    "                cats.append(np.zeros(3))\n",
    "                cats[-1][item] = 1.0\n",
    "            cat_sequences.append(cats)\n",
    "        return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38da22c4-35d7-42ea-b0c8-319df0494eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/x_tr_ortho.pkl', 'rb') as file:\n",
    "    x_tr_ortho = pickle.load(file)\n",
    "    # x_tr_ortho = x_tr_ortho.reshape(len(x_tr_ortho), 45, 1)\n",
    "    \n",
    "# with open('data/x_tr_ipa.pkl', 'rb') as file:\n",
    "#     x_tr_ipa = pickle.load(file)\n",
    "#     # x_tr_ipa = x_tr_ipa.reshape(len(x_tr_ipa), 74, 1)\n",
    "\n",
    "with open('data/false_ipa.pkl', 'rb') as file:\n",
    "    x_tr_ipa = pickle.load(file)\n",
    "    # x_tr_ipa = x_tr_ipa.reshape(len(x_tr_ipa), 74, 1)\n",
    "    \n",
    "with open('data/y_tr.pkl', 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "    y_tr = y_tr.reshape(len(y_tr), 74, 1)\n",
    "    \n",
    "y_tr = to_categorical(y_tr)\n",
    "split_index = int(.8 * len(x_tr_ortho))\n",
    "\n",
    "x_test_ortho = x_tr_ortho[split_index:]\n",
    "x_test_ipa = x_tr_ipa[split_index:]\n",
    "x_test_ipa = x_test_ipa.reshape(len(x_test_ipa), 74, 1)\n",
    "y_test = y_tr[split_index:]\n",
    "\n",
    "x_tr_ortho = x_tr_ortho[:split_index]\n",
    "x_tr_ipa = x_tr_ipa[:split_index]\n",
    "y_tr = y_tr[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e4f93-70f4-45aa-8fa6-21989772b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_tr_ipa))\n",
    "print(len(x_tr_ortho))\n",
    "print(len(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2289e2f-9c41-431d-8fb8-eb7d864c9f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 93s 2s/step - loss: 0.2913 - accuracy: 0.9017 - ignore_accuracy: 0.3612 - val_loss: 0.0869 - val_accuracy: 0.9776 - val_ignore_accuracy: 0.7828\n",
      "\n",
      "Epoch 00001: val_ignore_accuracy improved from -inf to 0.78279, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.0776 - accuracy: 0.9777 - ignore_accuracy: 0.7835 - val_loss: 0.0697 - val_accuracy: 0.9777 - val_ignore_accuracy: 0.7830\n",
      "\n",
      "Epoch 00002: val_ignore_accuracy improved from 0.78279 to 0.78296, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.0645 - accuracy: 0.9783 - ignore_accuracy: 0.7849 - val_loss: 0.0614 - val_accuracy: 0.9777 - val_ignore_accuracy: 0.7836\n",
      "\n",
      "Epoch 00003: val_ignore_accuracy improved from 0.78296 to 0.78356, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.0581 - accuracy: 0.9783 - ignore_accuracy: 0.7847 - val_loss: 0.0570 - val_accuracy: 0.9779 - val_ignore_accuracy: 0.7852\n",
      "\n",
      "Epoch 00004: val_ignore_accuracy improved from 0.78356 to 0.78522, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.0548 - accuracy: 0.9781 - ignore_accuracy: 0.7822 - val_loss: 0.0544 - val_accuracy: 0.9779 - val_ignore_accuracy: 0.7843\n",
      "\n",
      "Epoch 00005: val_ignore_accuracy did not improve from 0.78522\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.0525 - accuracy: 0.9784 - ignore_accuracy: 0.7860 - val_loss: 0.0524 - val_accuracy: 0.9781 - val_ignore_accuracy: 0.7863\n",
      "\n",
      "Epoch 00006: val_ignore_accuracy improved from 0.78522 to 0.78629, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 60s 2s/step - loss: 0.0506 - accuracy: 0.9786 - ignore_accuracy: 0.7876 - val_loss: 0.0506 - val_accuracy: 0.9782 - val_ignore_accuracy: 0.7871\n",
      "\n",
      "Epoch 00007: val_ignore_accuracy improved from 0.78629 to 0.78715, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.0486 - accuracy: 0.9792 - ignore_accuracy: 0.7931 - val_loss: 0.0485 - val_accuracy: 0.9789 - val_ignore_accuracy: 0.7939\n",
      "\n",
      "Epoch 00008: val_ignore_accuracy improved from 0.78715 to 0.79394, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.0461 - accuracy: 0.9804 - ignore_accuracy: 0.8054 - val_loss: 0.0454 - val_accuracy: 0.9809 - val_ignore_accuracy: 0.8132\n",
      "\n",
      "Epoch 00009: val_ignore_accuracy improved from 0.79394 to 0.81317, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 62s 2s/step - loss: 0.0426 - accuracy: 0.9829 - ignore_accuracy: 0.8317 - val_loss: 0.0407 - val_accuracy: 0.9849 - val_ignore_accuracy: 0.8519\n",
      "\n",
      "Epoch 00010: val_ignore_accuracy improved from 0.81317 to 0.85191, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 66s 2s/step - loss: 0.0380 - accuracy: 0.9859 - ignore_accuracy: 0.8599 - val_loss: 0.0368 - val_accuracy: 0.9866 - val_ignore_accuracy: 0.8691\n",
      "\n",
      "Epoch 00011: val_ignore_accuracy improved from 0.85191 to 0.86907, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 67s 2s/step - loss: 0.0351 - accuracy: 0.9871 - ignore_accuracy: 0.8725 - val_loss: 0.0349 - val_accuracy: 0.9873 - val_ignore_accuracy: 0.8762\n",
      "\n",
      "Epoch 00012: val_ignore_accuracy improved from 0.86907 to 0.87619, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 62s 2s/step - loss: 0.0336 - accuracy: 0.9875 - ignore_accuracy: 0.8769 - val_loss: 0.0339 - val_accuracy: 0.9877 - val_ignore_accuracy: 0.8799\n",
      "\n",
      "Epoch 00013: val_ignore_accuracy improved from 0.87619 to 0.87986, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 61s 2s/step - loss: 0.0322 - accuracy: 0.9883 - ignore_accuracy: 0.8841 - val_loss: 0.0327 - val_accuracy: 0.9881 - val_ignore_accuracy: 0.8840\n",
      "\n",
      "Epoch 00014: val_ignore_accuracy improved from 0.87986 to 0.88395, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 64s 2s/step - loss: 0.0313 - accuracy: 0.9885 - ignore_accuracy: 0.8858 - val_loss: 0.0320 - val_accuracy: 0.9881 - val_ignore_accuracy: 0.8833\n",
      "\n",
      "Epoch 00015: val_ignore_accuracy did not improve from 0.88395\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 63s 2s/step - loss: 0.0305 - accuracy: 0.9889 - ignore_accuracy: 0.8896 - val_loss: 0.0314 - val_accuracy: 0.9884 - val_ignore_accuracy: 0.8869\n",
      "\n",
      "Epoch 00016: val_ignore_accuracy improved from 0.88395 to 0.88695, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 63s 2s/step - loss: 0.0300 - accuracy: 0.9891 - ignore_accuracy: 0.8914 - val_loss: 0.0308 - val_accuracy: 0.9885 - val_ignore_accuracy: 0.8876\n",
      "\n",
      "Epoch 00017: val_ignore_accuracy improved from 0.88695 to 0.88762, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 67s 2s/step - loss: 0.0290 - accuracy: 0.9893 - ignore_accuracy: 0.8940 - val_loss: 0.0300 - val_accuracy: 0.9890 - val_ignore_accuracy: 0.8929\n",
      "\n",
      "Epoch 00018: val_ignore_accuracy improved from 0.88762 to 0.89293, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 66s 2s/step - loss: 0.0283 - accuracy: 0.9898 - ignore_accuracy: 0.8985 - val_loss: 0.0294 - val_accuracy: 0.9891 - val_ignore_accuracy: 0.8935\n",
      "\n",
      "Epoch 00019: val_ignore_accuracy improved from 0.89293 to 0.89349, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 67s 2s/step - loss: 0.0276 - accuracy: 0.9900 - ignore_accuracy: 0.9005 - val_loss: 0.0287 - val_accuracy: 0.9893 - val_ignore_accuracy: 0.8955\n",
      "\n",
      "Epoch 00020: val_ignore_accuracy improved from 0.89349 to 0.89552, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 67s 2s/step - loss: 0.0270 - accuracy: 0.9902 - ignore_accuracy: 0.9027 - val_loss: 0.0286 - val_accuracy: 0.9896 - val_ignore_accuracy: 0.8992\n",
      "\n",
      "Epoch 00021: val_ignore_accuracy improved from 0.89552 to 0.89915, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 67s 2s/step - loss: 0.0262 - accuracy: 0.9906 - ignore_accuracy: 0.9075 - val_loss: 0.0278 - val_accuracy: 0.9899 - val_ignore_accuracy: 0.9013\n",
      "\n",
      "Epoch 00022: val_ignore_accuracy improved from 0.89915 to 0.90126, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 65s 2s/step - loss: 0.0256 - accuracy: 0.9908 - ignore_accuracy: 0.9089 - val_loss: 0.0272 - val_accuracy: 0.9900 - val_ignore_accuracy: 0.9028\n",
      "\n",
      "Epoch 00023: val_ignore_accuracy improved from 0.90126 to 0.90282, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 65s 2s/step - loss: 0.0251 - accuracy: 0.9911 - ignore_accuracy: 0.9114 - val_loss: 0.0265 - val_accuracy: 0.9902 - val_ignore_accuracy: 0.9045\n",
      "\n",
      "Epoch 00024: val_ignore_accuracy improved from 0.90282 to 0.90454, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 65s 2s/step - loss: 0.0247 - accuracy: 0.9911 - ignore_accuracy: 0.9114 - val_loss: 0.0263 - val_accuracy: 0.9903 - val_ignore_accuracy: 0.9059\n",
      "\n",
      "Epoch 00025: val_ignore_accuracy improved from 0.90454 to 0.90592, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 68s 2s/step - loss: 0.0242 - accuracy: 0.9915 - ignore_accuracy: 0.9158 - val_loss: 0.0257 - val_accuracy: 0.9905 - val_ignore_accuracy: 0.9076\n",
      "\n",
      "Epoch 00026: val_ignore_accuracy improved from 0.90592 to 0.90759, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 69s 2s/step - loss: 0.0236 - accuracy: 0.9916 - ignore_accuracy: 0.9167 - val_loss: 0.0255 - val_accuracy: 0.9908 - val_ignore_accuracy: 0.9103\n",
      "\n",
      "Epoch 00027: val_ignore_accuracy improved from 0.90759 to 0.91031, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 67s 2s/step - loss: 0.0232 - accuracy: 0.9918 - ignore_accuracy: 0.9192 - val_loss: 0.0253 - val_accuracy: 0.9907 - val_ignore_accuracy: 0.9089\n",
      "\n",
      "Epoch 00028: val_ignore_accuracy did not improve from 0.91031\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 69s 2s/step - loss: 0.0228 - accuracy: 0.9919 - ignore_accuracy: 0.9210 - val_loss: 0.0247 - val_accuracy: 0.9910 - val_ignore_accuracy: 0.9120\n",
      "\n",
      "Epoch 00029: val_ignore_accuracy improved from 0.91031 to 0.91197, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 69s 2s/step - loss: 0.0224 - accuracy: 0.9921 - ignore_accuracy: 0.9225 - val_loss: 0.0245 - val_accuracy: 0.9911 - val_ignore_accuracy: 0.9127\n",
      "\n",
      "Epoch 00030: val_ignore_accuracy improved from 0.91197 to 0.91274, saving model to data\\false_double_pen_best_weights.h5\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 70s 2s/step - loss: 0.0222 - accuracy: 0.9922 - ignore_accuracy: 0.9208 - val_loss: 0.0248 - val_accuracy: 0.9908 - val_ignore_accuracy: 0.9103\n",
      "\n",
      "Epoch 00031: val_ignore_accuracy did not improve from 0.91274\n",
      "Epoch 32/50\n",
      "21/32 [==================>...........] - ETA: 22s - loss: 0.0220 - accuracy: 0.9919 - ignore_accuracy: 0.9200"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15172\\3003250690.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr_ortho\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tr_ipa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_ortho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_ipa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_filename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/false_double_pen_best_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Double_Pen_Syllabler\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_tr_ortho, x_tr_ipa, y_tr, x_test_ortho, x_test_ipa, y_test, ep, batch_size, save_filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mCallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         self.model.fit( x= [x_tr_ortho, x_tr_ipa],y=y_tr, epochs=ep, callbacks=Callbacks, batch_size=batch_size,\n\u001b[1;32m---> 72\u001b[1;33m                                 validation_data=([x_test_ortho, x_test_ipa], y_test))\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msyllabify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mipa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 _r=1):\n\u001b[0;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\laptop_sketchbook\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shitter.fit(x_tr_ortho[4000:], x_tr_ipa[4000:], y_tr[4000:], x_test_ortho, x_test_ipa, y_test, ep=50, batch_size=128, save_filename='data/false_double_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744471d9-32c8-41e2-8486-3ba1748cf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_to_eng(arr):\n",
    "    worded = []\n",
    "    for i in arr:\n",
    "        if i != 0:\n",
    "            worded += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    return worded\n",
    "\n",
    "def back_to_ipa(arr):\n",
    "    worded = []\n",
    "    for i in arr:\n",
    "        if i != 0:\n",
    "            worded += list(e2i_ipa.keys())[list(e2i_ipa.values()).index(i)]\n",
    "    return worded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997602f-244d-48be-ad61-5b77d60b7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shitter.model.load_weights('data/false_double_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111ba9b-d451-4848-96ab-5a4c305b8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ortho = ''.join(back_to_eng(x_test_ortho[7]))\n",
    "test_ipa = ''.join(back_to_ipa(x_test_ipa[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa45d7d-ce99-4973-aa83-86b098b8c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shitter.syllabify('', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbdd50-d1f0-49af-add4-966cb72c4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "'frumdafinkle', 'fɹʌmdʌfʌŋkʌl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51838a27-59c6-4498-b4cb-a449089e625e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10018 is out of bounds for axis 0 with size 8000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15172\\1257111078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10018\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 10018 is out of bounds for axis 0 with size 8000"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a415c-34bd-4089-b2c9-e298564589d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laptop_sketchbook",
   "language": "python",
   "name": "laptop_sketchbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

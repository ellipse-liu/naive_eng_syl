{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a9b17e-06a8-4275-bdf5-add205958c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Input, Embedding, Activation, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "import numpy as np\n",
    "from model import dp_syllabler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6b7972-fc36-4ba8-ad64-8cc1579e0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ortho max encoder len = 45\n",
    "#ipa max encoder len = 74\n",
    "\n",
    "with open('data/e2i_ortho.pkl', 'rb') as file:\n",
    "    e2i_ortho = pickle.load(file)\n",
    "    \n",
    "with open('data/e2i_ipa.pkl', 'rb') as file:\n",
    "    e2i_ipa = pickle.load(file)\n",
    "\n",
    "shitter = dp_syllabler(e2i_ortho= e2i_ortho, e2i_ipa = e2i_ipa, ortho_input_size=45,ipa_input_size=74,latent_dim=32,embed_dim=32 ,max_feat=148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4054e97-517f-4b07-90ff-7be738668746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences):\n",
    "        cat_sequences = []\n",
    "        for s in sequences:\n",
    "            cats = []\n",
    "            for item in s:\n",
    "                cats.append(np.zeros(3))\n",
    "                cats[-1][item] = 1.0\n",
    "            cat_sequences.append(cats)\n",
    "        return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38da22c4-35d7-42ea-b0c8-319df0494eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/x_tr_ortho.pkl', 'rb') as file:\n",
    "    x_tr_ortho = pickle.load(file)\n",
    "    # x_tr_ortho = x_tr_ortho.reshape(len(x_tr_ortho), 45, 1)\n",
    "    \n",
    "# with open('data/x_tr_ipa.pkl', 'rb') as file:\n",
    "#     x_tr_ipa = pickle.load(file)\n",
    "#     # x_tr_ipa = x_tr_ipa.reshape(len(x_tr_ipa), 74, 1)\n",
    "\n",
    "with open('data/false_ipa.pkl', 'rb') as file:\n",
    "    x_tr_ipa = pickle.load(file)\n",
    "    # x_tr_ipa = x_tr_ipa.reshape(len(x_tr_ipa), 74, 1)\n",
    "    \n",
    "with open('data/y_tr.pkl', 'rb') as file:\n",
    "    y_tr = pickle.load(file)\n",
    "    y_tr = y_tr.reshape(len(y_tr), 74, 1)\n",
    "    \n",
    "y_tr = to_categorical(y_tr)\n",
    "split_index = int(.8 * len(x_tr_ortho))\n",
    "\n",
    "x_test_ortho = x_tr_ortho[split_index:]\n",
    "x_test_ipa = x_tr_ipa[split_index:]\n",
    "x_test_ipa = x_test_ipa.reshape(len(x_test_ipa), 74, 1)\n",
    "y_test = y_tr[split_index:]\n",
    "\n",
    "x_tr_ortho = x_tr_ortho[:split_index]\n",
    "x_tr_ipa = x_tr_ipa[:split_index]\n",
    "y_tr = y_tr[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e4f93-70f4-45aa-8fa6-21989772b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_tr_ipa))\n",
    "print(len(x_tr_ortho))\n",
    "print(len(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2289e2f-9c41-431d-8fb8-eb7d864c9f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 95s 1s/step - loss: 0.0223 - accuracy: 0.9917 - ignore_accuracy: 0.9177 - val_loss: 0.0229 - val_accuracy: 0.9915 - val_ignore_accuracy: 0.9175\n",
      "\n",
      "Epoch 00001: val_ignore_accuracy improved from -inf to 0.91753, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 63s 997ms/step - loss: 0.0215 - accuracy: 0.9918 - ignore_accuracy: 0.9188 - val_loss: 0.0224 - val_accuracy: 0.9916 - val_ignore_accuracy: 0.9180\n",
      "\n",
      "Epoch 00002: val_ignore_accuracy improved from 0.91753 to 0.91797, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 0.0209 - accuracy: 0.9921 - ignore_accuracy: 0.9217 - val_loss: 0.0220 - val_accuracy: 0.9919 - val_ignore_accuracy: 0.9206\n",
      "\n",
      "Epoch 00003: val_ignore_accuracy improved from 0.91797 to 0.92060, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0206 - accuracy: 0.9921 - ignore_accuracy: 0.9217 - val_loss: 0.0216 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9219\n",
      "\n",
      "Epoch 00004: val_ignore_accuracy improved from 0.92060 to 0.92189, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 64s 1s/step - loss: 0.0201 - accuracy: 0.9923 - ignore_accuracy: 0.9242 - val_loss: 0.0215 - val_accuracy: 0.9920 - val_ignore_accuracy: 0.9224\n",
      "\n",
      "Epoch 00005: val_ignore_accuracy improved from 0.92189 to 0.92244, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0197 - accuracy: 0.9925 - ignore_accuracy: 0.9256 - val_loss: 0.0208 - val_accuracy: 0.9921 - val_ignore_accuracy: 0.9228\n",
      "\n",
      "Epoch 00006: val_ignore_accuracy improved from 0.92244 to 0.92280, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0194 - accuracy: 0.9926 - ignore_accuracy: 0.9271 - val_loss: 0.0208 - val_accuracy: 0.9921 - val_ignore_accuracy: 0.9227\n",
      "\n",
      "Epoch 00007: val_ignore_accuracy did not improve from 0.92280\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 63s 996ms/step - loss: 0.0193 - accuracy: 0.9926 - ignore_accuracy: 0.9270 - val_loss: 0.0204 - val_accuracy: 0.9922 - val_ignore_accuracy: 0.9242\n",
      "\n",
      "Epoch 00008: val_ignore_accuracy improved from 0.92280 to 0.92419, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0190 - accuracy: 0.9927 - ignore_accuracy: 0.9280 - val_loss: 0.0201 - val_accuracy: 0.9924 - val_ignore_accuracy: 0.9253\n",
      "\n",
      "Epoch 00009: val_ignore_accuracy improved from 0.92419 to 0.92531, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 63s 1000ms/step - loss: 0.0186 - accuracy: 0.9929 - ignore_accuracy: 0.9292 - val_loss: 0.0201 - val_accuracy: 0.9923 - val_ignore_accuracy: 0.9252\n",
      "\n",
      "Epoch 00010: val_ignore_accuracy did not improve from 0.92531\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 63s 997ms/step - loss: 0.0183 - accuracy: 0.9930 - ignore_accuracy: 0.9305 - val_loss: 0.0198 - val_accuracy: 0.9923 - val_ignore_accuracy: 0.9250\n",
      "\n",
      "Epoch 00011: val_ignore_accuracy did not improve from 0.92531\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0180 - accuracy: 0.9931 - ignore_accuracy: 0.9313 - val_loss: 0.0195 - val_accuracy: 0.9927 - val_ignore_accuracy: 0.9287\n",
      "\n",
      "Epoch 00012: val_ignore_accuracy improved from 0.92531 to 0.92869, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 63s 993ms/step - loss: 0.0177 - accuracy: 0.9932 - ignore_accuracy: 0.9328 - val_loss: 0.0194 - val_accuracy: 0.9927 - val_ignore_accuracy: 0.9284\n",
      "\n",
      "Epoch 00013: val_ignore_accuracy did not improve from 0.92869\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 0.0176 - accuracy: 0.9934 - ignore_accuracy: 0.9342 - val_loss: 0.0193 - val_accuracy: 0.9929 - val_ignore_accuracy: 0.9302\n",
      "\n",
      "Epoch 00014: val_ignore_accuracy improved from 0.92869 to 0.93019, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 64s 1s/step - loss: 0.0174 - accuracy: 0.9934 - ignore_accuracy: 0.9346 - val_loss: 0.0188 - val_accuracy: 0.9928 - val_ignore_accuracy: 0.9296\n",
      "\n",
      "Epoch 00015: val_ignore_accuracy did not improve from 0.93019\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 65s 1s/step - loss: 0.0171 - accuracy: 0.9935 - ignore_accuracy: 0.9351 - val_loss: 0.0189 - val_accuracy: 0.9929 - val_ignore_accuracy: 0.9311\n",
      "\n",
      "Epoch 00016: val_ignore_accuracy improved from 0.93019 to 0.93106, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 62s 992ms/step - loss: 0.0166 - accuracy: 0.9938 - ignore_accuracy: 0.9385 - val_loss: 0.0187 - val_accuracy: 0.9929 - val_ignore_accuracy: 0.9312\n",
      "\n",
      "Epoch 00017: val_ignore_accuracy improved from 0.93106 to 0.93119, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 62s 993ms/step - loss: 0.0166 - accuracy: 0.9937 - ignore_accuracy: 0.9373 - val_loss: 0.0185 - val_accuracy: 0.9930 - val_ignore_accuracy: 0.9318\n",
      "\n",
      "Epoch 00018: val_ignore_accuracy improved from 0.93119 to 0.93185, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 63s 995ms/step - loss: 0.0165 - accuracy: 0.9938 - ignore_accuracy: 0.9381 - val_loss: 0.0189 - val_accuracy: 0.9930 - val_ignore_accuracy: 0.9319\n",
      "\n",
      "Epoch 00019: val_ignore_accuracy improved from 0.93185 to 0.93195, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0163 - accuracy: 0.9939 - ignore_accuracy: 0.9394 - val_loss: 0.0185 - val_accuracy: 0.9927 - val_ignore_accuracy: 0.9288\n",
      "\n",
      "Epoch 00020: val_ignore_accuracy did not improve from 0.93195\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0160 - accuracy: 0.9940 - ignore_accuracy: 0.9401 - val_loss: 0.0183 - val_accuracy: 0.9929 - val_ignore_accuracy: 0.9311\n",
      "\n",
      "Epoch 00021: val_ignore_accuracy did not improve from 0.93195\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0159 - accuracy: 0.9940 - ignore_accuracy: 0.9408 - val_loss: 0.0182 - val_accuracy: 0.9931 - val_ignore_accuracy: 0.9322\n",
      "\n",
      "Epoch 00022: val_ignore_accuracy improved from 0.93195 to 0.93222, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 0.0157 - accuracy: 0.9941 - ignore_accuracy: 0.9417 - val_loss: 0.0183 - val_accuracy: 0.9930 - val_ignore_accuracy: 0.9317\n",
      "\n",
      "Epoch 00023: val_ignore_accuracy did not improve from 0.93222\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0155 - accuracy: 0.9942 - ignore_accuracy: 0.9426 - val_loss: 0.0179 - val_accuracy: 0.9933 - val_ignore_accuracy: 0.9348\n",
      "\n",
      "Epoch 00024: val_ignore_accuracy improved from 0.93222 to 0.93475, saving model to data\\32_false_double_pen_best_weights.h5\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 63s 997ms/step - loss: 0.0153 - accuracy: 0.9943 - ignore_accuracy: 0.9433 - val_loss: 0.0180 - val_accuracy: 0.9930 - val_ignore_accuracy: 0.9318\n",
      "\n",
      "Epoch 00025: val_ignore_accuracy did not improve from 0.93475\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0151 - accuracy: 0.9943 - ignore_accuracy: 0.9438 - val_loss: 0.0180 - val_accuracy: 0.9932 - val_ignore_accuracy: 0.9339\n",
      "\n",
      "Epoch 00026: val_ignore_accuracy did not improve from 0.93475\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 63s 1s/step - loss: 0.0149 - accuracy: 0.9945 - ignore_accuracy: 0.9453 - val_loss: 0.0179 - val_accuracy: 0.9932 - val_ignore_accuracy: 0.9339\n",
      "\n",
      "Epoch 00027: val_ignore_accuracy did not improve from 0.93475\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "shitter.fit(x_tr_ortho, x_tr_ipa, y_tr, x_test_ortho, x_test_ipa, y_test, ep=50, batch_size=128, save_filename='data/32_false_double_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997602f-244d-48be-ad61-5b77d60b7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shitter.model.load_weights('data/false_double_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111ba9b-d451-4848-96ab-5a4c305b8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ortho = ''.join(back_to_eng(x_test_ortho[7]))\n",
    "test_ipa = ''.join(back_to_ipa(x_test_ipa[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aa45d7d-ce99-4973-aa83-86b098b8c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tink-le\n"
     ]
    }
   ],
   "source": [
    "print(shitter.syllabify('tinkle', ippa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7bbdd50-d1f0-49af-add4-966cb72c4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "ippa = get_naive('tinkle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51838a27-59c6-4498-b4cb-a449089e625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2i = {'a':'æ', 'b':'b', 'c':'k', 'd':'d', 'e':'e', 'f':'f' , 'g':'g', 'h':'h', 'i':'ɪ', 'j':'ʒ', 'k':'k', 'l':'l', 'm':'m', 'n':'n',\n",
    "      'o':'ɑ', 'p':'p', 'q':'k', 'r':'ɹ', 's':'s', 't':'t', 'u':'ə', 'v':'v', 'w':'w', 'x':['k','s'], 'y':'j', 'z':'z'}\n",
    "\n",
    "def get_naive(word):\n",
    "    naive = []\n",
    "    for c in word:\n",
    "        naive += l2i[c]\n",
    "    naive = ''.join(naive)\n",
    "    return naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a415c-34bd-4089-b2c9-e298564589d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laptop_sketchbook",
   "language": "python",
   "name": "laptop_sketchbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f64d5aa4-2eb2-4429-9098-0c01d92ed943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dp_syllabler\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d007baa1-be24-4ebe-bb56-1178363ca328",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/x_val_ortho.pkl', 'rb') as file:\n",
    "    x_val_ortho = pickle.load(file)\n",
    "    \n",
    "with open('data/x_val_ipa.pkl', 'rb') as file:\n",
    "    x_val_ipa = pickle.load(file)\n",
    "\n",
    "with open('data/y_val.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "    \n",
    "with open('data/x_tr_ortho.pkl', 'rb') as file:\n",
    "    x_tr_ortho = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872fad00-95ba-4400-9829-1e9d02674830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ortho max encoder len = 45\n",
    "#ipa max encoder len = 74\n",
    "\n",
    "with open('data/e2i_ortho.pkl', 'rb') as file:\n",
    "    e2i_ortho = pickle.load(file)\n",
    "    \n",
    "with open('data/e2i_ipa.pkl', 'rb') as file:\n",
    "    e2i_ipa = pickle.load(file)\n",
    "\n",
    "double_penetrator = dp_syllabler(e2i_ortho= e2i_ortho, e2i_ipa = e2i_ipa, ortho_input_size=45,ipa_input_size=74,latent_dim=32,embed_dim=32 ,max_feat=148)\n",
    "double_penetrator.model.load_weights('data/32_false_double_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba37d7ae-d302-4cd7-a63d-8fce51e9b56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_f1(attempted, true, filename = 'data/evaluation_output_double_pen.txt'):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    correct_num_char = 0\n",
    "    total_checked = 0\n",
    "    evaluation_file = open(filename, 'w+')\n",
    "    for i in range(0, len(attempted)):\n",
    "        total_checked += 1\n",
    "        if (len(attempted[i]) == len(true[i])):\n",
    "            correct_num_char += 1\n",
    "            for j in range(0, len(attempted[i])):\n",
    "                if(attempted[i][j] == true[i][j]):\n",
    "                    if true[i][j] == 1:\n",
    "                        true_neg += 1\n",
    "                    elif true[i][j] == 2:\n",
    "                        true_pos += 1\n",
    "                else:\n",
    "                    if true[i][j] == 1:\n",
    "                        false_pos += 1\n",
    "                    elif true[i][j] == 2:\n",
    "                        false_neg += 1\n",
    "    evaluation_file.write(\"Total checked: \" + str(total_checked) + '\\n')\n",
    "    evaluation_file.write(\"Num correctly evaluated character count: \" +  str(correct_num_char) + '\\n')\n",
    "    evaluation_file.write(\"True positives: \" + str(true_pos) + '\\n')\n",
    "    evaluation_file.write(\"True negatives: \" + str(true_neg) + '\\n')\n",
    "    evaluation_file.write(\"False positives: \" + str(false_pos) + '\\n')\n",
    "    evaluation_file.write(\"False negatives: \" + str(false_neg) + '\\n')\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos + false_neg)\n",
    "    f_one = 2/((1/precision)+(1/recall))\n",
    "    evaluation_file.write(\"precision: \" + str(precision) + '\\n')\n",
    "    evaluation_file.write(\"recall: \" + str(recall) +  '\\n')\n",
    "    evaluation_file.write(\"F1 scores: \" + str(f_one) + '\\n')\n",
    "    evaluation_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e720948-dc54-458b-b8ea-e76505bb89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = []\n",
    "for x in y_val:\n",
    "    reals += [[i for i in x if i !=0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce64d07a-97e0-452e-855b-9b4dfda0cb51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\r"
     ]
    }
   ],
   "source": [
    "attempts = []\n",
    "for i in range(0, 5000):\n",
    "    attempts += [double_penetrator.raw_syllabify(x_val_ortho[i], false_ipa[i])]\n",
    "    print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5129ebca-d138-4be6-b50c-a0afd73faea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts_stripped = []\n",
    "for x in attempts:\n",
    "    attempts_stripped += [[i for i in x if i !=0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae52e7c2-4bd1-4fc1-bb26-458a1612c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_f1(attempts_stripped, reals, 'data/32_pure_false_evaluation_output.txt')\n",
    "inconsistency_grab(attempts_stripped, reals, 'data/32_incorrect_syls.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee990122-bd1b-49d6-b55b-169903f5ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inconsistency_grab(attempts, reals, filename = 'data/incorrect_syls.txt'):\n",
    "    global converted_back_to_eng\n",
    "    incorrect_counter = 0\n",
    "    file = open(filename, 'w+')\n",
    "    file.write('Attempt' + '\\t' + 'Real' + '\\n')\n",
    "    for i in range(0, len(attempts)):\n",
    "        if attempts[i] != reals[i]:\n",
    "            incorrect_counter += 1\n",
    "            a = double_penetrator.insert_syl(converted_back_to_eng[i], attempts[i])\n",
    "            r = double_penetrator.insert_syl(converted_back_to_eng[i], reals[i])\n",
    "            file.write(a + '\\t' + r + '\\n')\n",
    "    file.write(\"Words with errors: %i\"%incorrect_counter +'\\n')\n",
    "    file.write(\"Total evluated: %i\"%len(attempts) +'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c971de7-c80b-4a36-add8-b56544905def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eng_conv_attempts = []\n",
    "for i in range(0, len(attempts)):\n",
    "    eng_conv_attempts += [double_penetrator.insert_syl(converted_back_to_eng[i], attempts[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638b60d0-bf6f-4f3a-b7ac-7fa382ef3cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "converted_back_to_eng = []\n",
    "for x in x_val_ortho:\n",
    "    real_word = \"\"\n",
    "    for i in x:\n",
    "            if i != 0:\n",
    "                real_word += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    converted_back_to_eng += [real_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf653dcb-d244-4cf6-9607-ba23b152addd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing with falses\n",
    "attempts_prime = []\n",
    "for i in range(0, 5000):\n",
    "    attempts_prime += [double_penetrator.raw_syllabify(x_val_ortho[i], np.array(false_ipa[i]))]\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "attempts_prime_stripped = []\n",
    "for x in attempts_prime:\n",
    "    attempts_prime_stripped += [[i for i in x if i !=0]]\n",
    "    \n",
    "calc_f1(attempts_prime_stripped, reals, 'data/falses_evaluation_output_double_pen.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d5f0a-4de6-49dc-9e34-8b2ca9776a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/eng_words.txt','w+') as file:\n",
    "    for i in range(0,5000):\n",
    "        file.write(converted_back_to_eng[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6bb72-8c73-4d85-8d51-0fd162836152",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# falsing training data\n",
    "tr_converted_back_to_eng = []\n",
    "for x in x_tr_ortho:\n",
    "    real_word = \"\"\n",
    "    for i in x:\n",
    "            if i != 0:\n",
    "                real_word += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    tr_converted_back_to_eng += [real_word]\n",
    "\n",
    "\n",
    "false_ipa_orig = []\n",
    "false_ipa = []\n",
    "\n",
    "for i in range(0,len(x_tr_ortho)):\n",
    "    tried = []\n",
    "    for q in tr_converted_back_to_eng[i]:\n",
    "        tried += l2i[q]\n",
    "    false_ipa_orig += [tried]\n",
    "    \n",
    "for x in false_ipa_orig:\n",
    "    inted = []\n",
    "    for y in x:\n",
    "        inted += [e2i_ipa[y]]\n",
    "    false_ipa += [inted]\n",
    "        \n",
    "    \n",
    "false_ipa = pad_sequences(false_ipa, maxlen=74, padding='post')\n",
    "\n",
    "with open('data/false_ipa.pkl', 'wb+') as file:\n",
    "    pickle.dump(false_ipa, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468fecc7-c253-450f-a667-df5750d0dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2i = {'a':'æ', 'b':'b', 'c':'k', 'd':'d', 'e':'e', 'f':'f' , 'g':'g', 'h':'h', 'i':'ɪ', 'j':'ʒ', 'k':'k', 'l':'l', 'm':'m', 'n':'n',\n",
    "      'o':'ɑ', 'p':'p', 'q':'k', 'r':'ɹ', 's':'s', 't':'t', 'u':'ə', 'v':'v', 'w':'w', 'x':['k','s'], 'y':'j', 'z':'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98fadf1-2ee2-4d54-b0e4-38936386474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_converted_back_to_eng = []\n",
    "for x in x_val_ortho:\n",
    "    real_word = \"\"\n",
    "    for i in x:\n",
    "            if i != 0:\n",
    "                real_word += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    val_converted_back_to_eng += [real_word]\n",
    "\n",
    "false_ipa_orig = []\n",
    "false_ipa = []\n",
    "\n",
    "for i in range(0,len(x_val_ortho)):\n",
    "    tried = []\n",
    "    for q in val_converted_back_to_eng[i]:\n",
    "        tried += l2i[q]\n",
    "    false_ipa_orig += [tried]\n",
    "    \n",
    "for x in false_ipa_orig:\n",
    "    inted = []\n",
    "    for y in x:\n",
    "        inted += [e2i_ipa[y]]\n",
    "    false_ipa += [inted]\n",
    "        \n",
    "    \n",
    "false_ipa = pad_sequences(false_ipa, maxlen=74, padding='post')\n",
    "\n",
    "with open('data/false_val_ipa.pkl', 'wb+') as file:\n",
    "    pickle.dump(false_ipa, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8d28d-080d-4205-8f2d-42b602c80647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laptop_sketchbook",
   "language": "python",
   "name": "laptop_sketchbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
